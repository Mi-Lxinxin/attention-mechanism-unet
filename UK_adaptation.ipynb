{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48338332",
   "metadata": {},
   "source": [
    "## 1) Problem, SDG alignment, limitations, scalability\n",
    "\n",
    "**Problem:** Detect recent tree-cover loss / woodland removal events in the UK using Sentinel‑2 optical imagery.\n",
    "\n",
    "**SDG alignment:**\n",
    "- SDG 15 (Life on Land): monitoring forest and woodland loss.\n",
    "- SDG 13 (Climate Action): quantify loss/impact on carbon sinks.\n",
    "\n",
    "**Limitations & ethical considerations:**\n",
    "- GFC labels are produced globally and may mislabel non-forest land uses in temperate regions (label noise).\n",
    "- Optical sensors are affected by clouds; cloud masking or multi-date imagery recommended.\n",
    "- False positives/negatives have socio-economic implications (landowners, policy) — include uncertainty reporting and avoid direct enforcement actions based solely on model output.\n",
    "- Ensure attribution to data providers and follow licenses for GFC and Sentinel data.\n",
    "\n",
    "**Scalability & sustainability:**\n",
    "- The pipeline can scale horizontally by processing tiles in parallel (Dask, Spark).\n",
    "- For continual monitoring, deploy lightweight models with periodic retraining using new labels; consider model quantization for edge or serverless deployments.\n",
    "- Use cloud-hosted STAC and object storage for large-scale ingestion; keep preprocessing simple (patching) to reduce compute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305e87c",
   "metadata": {},
   "source": [
    "## 2) Dataset selection and access\n",
    "\n",
    "Inputs (image): Sentinel‑2 L2A (bands B02, B03, B04, B08) — 10 m resolution.\n",
    "\n",
    "Labels (ground truth): Hansen Global Forest Change (GFC) `lossyear` or `loss` raster — 30 m resolution. We'll derive a binary mask (loss occurred within a selected time window).\n",
    "\n",
    "Data access options:\n",
    "- Sentinel‑2: AWS public `s3://sentinel-s2-l2a` or Copernicus Open Access Hub / STAC. For this notebook we assume you have relevant Sentinel‑2 tiles locally (download one sample tile and place in `data/sentinel/`).\n",
    "- GFC: download region subset from Global Forest Watch or Google Cloud public bucket and place in `data/gfc/`.\n",
    "\n",
    "Rationale: Sentinel‑2 provides the 4 bands used in the original paper 4‑band model; GFC provides consistent loss labels across global regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a56dde",
   "metadata": {},
   "source": [
    "## 3) Preprocessing pipeline — approach summary\n",
    "\n",
    "Goals:\n",
    "- Read Sentinel‑2 4‑band images and normalize to 0–1.\n",
    "- Read GFC loss raster, reproject and resample to Sentinel grid (recommended: resample labels to 10 m using nearest-neighbour to avoid smoothing).\n",
    "- Create binary mask for loss within a chosen year range (e.g., 2015–2024).\n",
    "- Cut 512×512 patches with matching image and mask pairs and save as NumPy arrays matching shapes used in repository (512×512×4 and 512×512×1).\n",
    "\n",
    "Notes: The code below expects local files; replace paths with your downloaded tile/label files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5609015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.warp import calculate_default_transform, reproject\n",
    "from affine import Affine\n",
    "from tqdm import tqdm\n",
    "\n",
    "def read_sentinel_tile(path_b02, path_b03, path_b04, path_b08):\n",
    "    \"\"\"Read 4 bands and stack into (H,W,4) float32 array normalized 0-1.\"\"\"\n",
    "    bands = []\n",
    "    for p in [path_b02, path_b03, path_b04, path_b08]:\n",
    "        da = rxr.open_rasterio(p, masked=True)\n",
    "        arr = np.array(da.squeeze())\n",
    "        bands.append(arr)\n",
    "    img = np.stack(bands, axis=-1).astype('float32')\n",
    "    # simple normalization per-tile (scale to 0-1 using tile min/max)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-9)\n",
    "    return img, da.rio.transform(), da.rio.crs\n",
    "def read_gfc_mask(path_gfc, target_crs, target_transform, target_shape, year_min=None, year_max=None):\n",
    "    \"\"\"Read GFC loss raster and resample + reproject to target grid. Returns binary mask aligned to image.\"\"\"\n",
    "    src = rasterio.open(path_gfc)\n",
    "    # Read entire dataset (careful for large files) — user should subset to AOI before using.\n",
    "    data = src.read(1)\n",
    "    # If values represent lossyear, create boolean mask for chosen years\n",
    "    if year_min is not None or year_max is not None:\n",
    "        mask = np.zeros_like(data, dtype=np.uint8)\n",
    "        if year_min is None: year_min = 1\n",
    "        if year_max is None: year_max = 9999\n",
    "        # Hansen uses year values 1.. (e.g., 2001->1) or 'loss' boolean; adapt accordingly.\n",
    "        # Here we interpret >0 as loss and ignore year mapping complexity; user can adapt.\n",
    "        mask[(data >= year_min) & (data <= year_max)] = 1\n",
    "    else:\n",
    "        mask = (data > 0).astype(np.uint8)\n",
    "\n",
    "    # Reproject/resample to target grid\n",
    "    dst = np.zeros(target_shape, dtype=np.uint8)\n",
    "    reproject(\n",
    "        source=mask,\n",
    "        destination=dst,\n",
    "        src_transform=src.transform,\n",
    "        src_crs=src.crs,\n",
    "        dst_transform=target_transform,\n",
    "        dst_crs=target_crs,\n",
    "        resampling=Resampling.nearest\n",
    "    )\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e04af6",
   "metadata": {},
   "source": [
    "### Patch extraction function — creates 512×512 patches and saves numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af578ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(image, mask, out_dir, prefix='uk', patch_size=512, stride=512, min_mask_coverage=0.001):\n",
    "    \"\"\"Slide window patches across image and save pairs where mask coverage passes threshold.\n",
    "    image: HxWxC, mask: HxW (binary).\"\"\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    H, W = image.shape[:2]\n",
    "    idx = 0\n",
    "    for y in range(0, H - patch_size + 1, stride):\n",
    "        for x in range(0, W - patch_size + 1, stride):\n",
    "            img_patch = image[y:y+patch_size, x:x+patch_size, :]\n",
    "            m_patch = mask[y:y+patch_size, x:x+patch_size]\n",
    "            coverage = m_patch.mean()\n",
    "            if coverage >= min_mask_coverage or True:  # saving all patches by default; change as needed\n",
    "                np.save(os.path.join(out_dir, f\"{prefix}_img_{idx}.npy\"), img_patch.astype('float32'))\n",
    "                np.save(os.path.join(out_dir, f\"{prefix}_mask_{idx}.npy\"), m_patch.reshape(patch_size, patch_size, 1).astype('uint8'))\n",
    "                idx += 1\n",
    "    print(f'Wrote {idx} patches to {out_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e60077",
   "metadata": {},
   "source": [
    "## 4) Model adaptation — Attention U‑Net for 4‑band input\n",
    "\n",
    "We adapt the Attention U‑Net to accept 4 input channels (Sentinel B02,B03,B04,B08). The architecture and attention gates are the same as the original, with input shape (512,512,4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b38d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D, concatenate, Activation, Multiply, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def conv_block(x, filters, kernel_size=3, activation='relu'):\n",
    "    x = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = Conv2D(filters, kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x\n",
    "\n",
    "def attention_gate(x, g, inter_channels):\n",
    "    # x: skip connection, g: gating signal\n",
    "    theta_x = Conv2D(inter_channels, 1, strides=1, padding='same')(x)\n",
    "    phi_g = Conv2D(inter_channels, 1, strides=1, padding='same')(g)\n",
    "    add_xg = Activation('relu')(Add()([theta_x, phi_g]))\n",
    "    psi = Conv2D(1, 1, padding='same')(add_xg)\n",
    "    psi = Activation('sigmoid')(psi)\n",
    "    return Multiply()([x, psi])\n",
    "\n",
    "def build_attention_unet(input_shape=(512,512,4), base_filters=16, lr=5e-4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # encoder\n",
    "    c1 = conv_block(inputs, base_filters)\n",
    "    p1 = MaxPooling2D()(c1)\n",
    "    c2 = conv_block(p1, base_filters*2)\n",
    "    p2 = MaxPooling2D()(c2)\n",
    "    c3 = conv_block(p2, base_filters*4)\n",
    "    p3 = MaxPooling2D()(c3)\n",
    "    c4 = conv_block(p3, base_filters*8)\n",
    "    p4 = MaxPooling2D()(c4)\n",
    "    c5 = conv_block(p4, base_filters*16)\n",
    "    # decoder with attention gates\n",
    "    u4 = Conv2DTranspose(base_filters*8, 2, strides=2, padding='same')(c5)\n",
    "    att4 = attention_gate(c4, c5, base_filters*8)\n",
    "    m4 = concatenate([u4, att4])\n",
    "    c6 = conv_block(m4, base_filters*8)\n",
    "    u3 = Conv2DTranspose(base_filters*4, 2, strides=2, padding='same')(c6)\n",
    "    att3 = attention_gate(c3, c6, base_filters*4)\n",
    "    m3 = concatenate([u3, att3])\n",
    "    c7 = conv_block(m3, base_filters*4)\n",
    "    u2 = Conv2DTranspose(base_filters*2, 2, strides=2, padding='same')(c7)\n",
    "    att2 = attention_gate(c2, c7, base_filters*2)\n",
    "    m2 = concatenate([u2, att2])\n",
    "    c8 = conv_block(m2, base_filters*2)\n",
    "    u1 = Conv2DTranspose(base_filters, 2, strides=2, padding='same')(c8)\n",
    "    att1 = attention_gate(c1, c8, base_filters)\n",
    "    m1 = concatenate([u1, att1])\n",
    "    c9 = conv_block(m1, base_filters)\n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(c9)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Example build\n",
    "model = build_attention_unet(input_shape=(512,512,4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0a843",
   "metadata": {},
   "source": [
    "## 5) Training routine and hyperparameter tuning notes\n",
    "\n",
    "Notes:\n",
    "- Use class imbalance strategies: weighted loss (compute class weights from patches) or focal loss.\n",
    "- Suggested hyperparameter sweep: learning rate (5e-5, 1e-4, 5e-4), batch size (4,8), patch_size (256 or 512), augmentation strength.\n",
    "- Use early stopping and ModelCheckpoint to keep best validation model.\n",
    "\n",
    "The training cell below uses Keras `fit` with data loaded from saved `.npy` patch files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d674ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def load_patches(patch_dir, n=None):\n",
    "    imgs = sorted(glob.glob(os.path.join(patch_dir, '*_img_*.npy')))\n",
    "    masks = sorted(glob.glob(os.path.join(patch_dir, '*_mask_*.npy')))\n",
    "    if n is not None:\n",
    "        imgs = imgs[:n]; masks = masks[:n]\n",
    "    X = [np.load(p) for p in imgs]\n",
    "    y = [np.load(p) for p in masks]\n",
    "    X = np.stack(X).astype('float32')\n",
    "    y = np.stack(y).astype('uint8')\n",
    "    return X, y\n",
    "\n",
    "# Example: load small subset for quick test\n",
    "PATCH_DIR = 'data/patches'\n",
    "if os.path.exists(PATCH_DIR):\n",
    "    X, y = load_patches(PATCH_DIR, n=100)  # load first 100 pairs for quick run\n",
    "    print('X', X.shape, 'y', y.shape)\n",
    "    # split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = build_attention_unet(input_shape=(512,512,4), base_filters=16, lr=5e-4)\n",
    "    cb = [ModelCheckpoint('uk_unet_att.h5', monitor='val_loss', save_best_only=True), EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)]\n",
    "    # quick training for demonstration; set epochs higher for real runs\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=4, callbacks=cb)\n",
    "else:\n",
    "    print('No patches found in', PATCH_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ab293",
   "metadata": {},
   "source": [
    "## 6) Evaluation and statistical testing\n",
    "\n",
    "We compute IoU (Jaccard), Dice, Precision, Recall and F1 on the validation/test set. To test statistical significance of differences vs. baseline, we use bootstrap resampling of per-patch IoU scores and calculate confidence intervals and p‑value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3606c1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def iou_score(y_true, y_pred, eps=1e-7):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = (y_pred.flatten() > 0.5).astype(int)\n",
    "    inter = (y_true & y_pred).sum()\n",
    "    union = (y_true | y_pred).sum()\n",
    "    if union == 0: return 1.0 if inter==0 else 0.0\n",
    "    return inter / (union + eps)\n",
    "\n",
    "def dice_score(y_true, y_pred, eps=1e-7):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = (y_pred.flatten() > 0.5).astype(int)\n",
    "    inter = (y_true & y_pred).sum()\n",
    "    return (2 * inter) / (y_true.sum() + y_pred.sum() + eps)\n",
    "\n",
    "def evaluate_model(model, X, y):\n",
    "    ious = []; dices = []; precisions = []; recalls = []; f1s = []\n",
    "    preds = model.predict(X, batch_size=4)\n",
    "    for i in range(len(X)):\n",
    "        gt = y[i].reshape(-1)\n",
    "        pr = preds[i].reshape(-1)\n",
    "        iou = iou_score(gt, pr)\n",
    "        dice = dice_score(gt, pr)\n",
    "        p = precision_score(gt, (pr>0.5).astype(int), zero_division=0)\n",
    "        r = recall_score(gt, (pr>0.5).astype(int), zero_division=0)\n",
    "        f1 = 2*p*r / (p+r+1e-7) if (p+r)>0 else 0.0\n",
    "        ious.append(iou); dices.append(dice); precisions.append(p); recalls.append(r); f1s.append(f1)\n",
    "    return {'iou': np.array(ious), 'dice': np.array(dices), 'precision': np.array(precisions), 'recall': np.array(recalls), 'f1': np.array(f1s)}\n",
    "\n",
    "def bootstrap_compare(metric_a, metric_b, n_boot=1000):\n",
    "    # metric_a and metric_b are arrays of per-sample scores (same length)\n",
    "    diff = metric_a - metric_b\n",
    "    n = len(diff)\n",
    "    boot_diffs = []\n",
    "    rng = np.random.default_rng(42)\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, n)\n",
    "        boot_diffs.append(diff[idx].mean())\n",
    "    boot_diffs = np.array(boot_diffs)\n",
    "    ci_low = np.percentile(boot_diffs, 2.5)\n",
    "    ci_high = np.percentile(boot_diffs, 97.5)\n",
    "    p_value = (np.sum(boot_diffs <= 0) / n_boot)  # one-sided test for A>B\n",
    "    return {'mean_diff': diff.mean(), 'ci': (ci_low, ci_high), 'p_value': p_value}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fec592",
   "metadata": {},
   "source": [
    "## 7) Failure analysis and visualization helpers\n",
    "\n",
    "- Visualize false positives and false negatives to understand common failure modes.\n",
    "- Stratify errors by landcover or season if metadata available.\n",
    "\n",
    "The cell below provides simple visualization utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c79767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_case(X, y_true, y_pred, idx=0):\n",
    "    fig, axs = plt.subplots(1,4, figsize=(16,4))\n",
    "    axs[0].imshow(X[idx][..., :3])\n",
    "    axs[0].set_title('RGB preview')\n",
    "    axs[1].imshow(y_true[idx].squeeze(), cmap='gray')\n",
    "    axs[1].set_title('Ground truth')\n",
    "    axs[2].imshow((y_pred[idx].squeeze()>0.5).astype(int), cmap='gray')\n",
    "    axs[2].set_title('Prediction')\n",
    "    axs[3].imshow((y_pred[idx].squeeze()>0.5).astype(int) - y_true[idx].squeeze(), cmap='bwr')\n",
    "    axs[3].set_title('Error (pred - gt)')\n",
    "    for a in axs: a.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
